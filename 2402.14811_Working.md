### Focuses on the mechanism of fine-tuning and how it improves language models' capabilities by circuit preservation & enhancement

**How Does Fine-Tuning Improve Language Models' Capabilities?**
 - Fine-tuning has become a ubiquitous technique for enhancing language models' capabilities across diverse tasks. However, the mechanistic updates underpinning these performance gains remain poorly understood. Does the fine-tuned model employ the same mechanism, or does it modify its algorithm to address a task? Are the same set of model components (i.e. circuit) engaged in performing the task, or are different ones involved?

 ### Our findings suggest that fine-tuning enhances, rather than fundamentally alters, the mechanistic operation of the model. Specifically, *we observed that the task of entity tracking in Llama-7B and its fine-tuned variants is primarily performed by the same circuit. Not only are the same set of components involved, but their functionality also remains consistent across the models.* Finally, we were able to attribute the performance gap to an improved sub-mechansim in the fine-tuned models.

 - **Fine-tuning improves performance primarily by enhancing an existing circuit/mechanism already present in the base model, rather than creating a qualitatively different mechanism.**

 ### For entity tracking, they find:

1. The same sparse entity-tracking circuit (a specific set of attention heads at specific token positions) exists in LLaMA‑7B and all fine‑tuned variants.

2. Functionally, the circuit works the same way across models: it tracks entities by passing around positional information about where the relevant object token is, and then “fetching” that value at the end.

3. Fine‑tuning mainly augments positional encoding and value-retrieval quality in that same circuit and adds extra heads around it, but does not change the underlying algorithm.

### Path Patching (Elhage et al. / Wang et al.)
– Causally patch activations along specific paths between attention heads and see how that affects the probability of the correct answer.

~~300 dataset examples
score = (Ppatch - Porg) / Porg


# Catastrophic Forgetting
**Our work - When fine-tuning learns new tasks, which fine-tuning method (SFT vs RL) better preserves old circuits?**
Focus - Circuit preservation under task interference